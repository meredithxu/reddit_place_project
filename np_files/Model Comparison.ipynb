{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine whether to use the GradientBoostingRegressor from sklearn or a Neural Network.\n",
    "Evaluate which model gets better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import scipy\n",
    "import networkx as nx\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "import operator\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../Python_code\") # go to parent dir\n",
    "from canvas_vis import * \n",
    "from analytics_combined import *\n",
    "from generate_proj_to_remove import *\n",
    "from project_data_analysis import *\n",
    "from user_embedding import *\n",
    "from segmentation import *\n",
    "from evaluation import *\n",
    "from nonlinear_regressor import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the size of the canvas that is being looked at\n",
    "min_x = 0\n",
    "max_x = 10\n",
    "min_y = 0\n",
    "max_y = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_to_remove = get_list_of_removed_proj(output_filename = \"../data/proj_to_remove.txt\")\n",
    "\n",
    "input_file= \"../data/sorted_tile_placements_proj.csv\"\n",
    "js_filename = \"../data/atlas_complete.json\"\n",
    "\n",
    "names, descriptions = read_picture_names_and_descriptions(js_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num edges =  326217\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO: How far two vertices should be to be connected (1-4)?\n",
    "G, ups = create_graph(input_file, projects_to_remove, 4, min_x, max_x, min_y, max_y, file_prefix=\"comparison\")\n",
    "\n",
    "print(\"num edges = \", G.n_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open('graph_10x10.pkl', 'wb')\n",
    "pickle.dump(G, pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open('ups_10x10.pkl', 'wb')\n",
    "pickle.dump(ups, pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open('graph_10x10.pkl', 'rb')\n",
    "G = pickle.load(pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open('ups_10x10.pkl', 'rb')\n",
    "ups = pickle.load(pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining 7 edge features and computing the information they require\n",
    "#Adding a new feature without changing the rest of the code should\n",
    "#be easy.\n",
    "#TODO: Are there other features that would improve the segmentation?\n",
    "#TODO: How many dimensions we need?\n",
    "\n",
    "def different_color(i, j, ups, data=None):\n",
    "    if ups[i][4] == ups[j][4]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "        \n",
    "def distance_space(i, j, ups, data=None):\n",
    "    xi = ups[i][2]\n",
    "    yi = ups[i][3]\n",
    "    xj = ups[j][2]\n",
    "    yj = ups[j][3]\n",
    "    \n",
    "    return np.sqrt(pow(xi-xj,2)+pow(yi-yj,2))\n",
    "\n",
    "def distance_time(i, j, ups, data=None):\n",
    "    time_i = ups[i][0]\n",
    "    time_j = ups[j][0]\n",
    "    \n",
    "    return np.sqrt(pow(time_i-time_j,2))\n",
    "\n",
    "def distance_duration(i, j, ups, durations):\n",
    "    return dist_duration(durations[i], durations[j])\n",
    "\n",
    "def distance_color(i, j, ups, conflicts):\n",
    "    color_i = ups[i][4]\n",
    "    color_j = ups[j][4]\n",
    "    \n",
    "    if color_i == color_j:\n",
    "        return 0\n",
    "    else:\n",
    "        max_up = len(ups)\n",
    "        dist = 0\n",
    "        \n",
    "        conf_i = []\n",
    "        if conflicts[i][0] <= max_up:\n",
    "            conf_i.append(ups[conflicts[i][0]][4])\n",
    "            \n",
    "        if conflicts[i][1] <= max_up:\n",
    "            conf_i.append(ups[conflicts[i][1]][4])\n",
    "        \n",
    "        conf_j = []\n",
    "        if conflicts[j][0] <= max_up:\n",
    "            conf_j.append(ups[conflicts[j][0]][4])\n",
    "            \n",
    "        if conflicts[j][1] <= max_up:\n",
    "            conf_j.append(ups[conflicts[j][1]][4])\n",
    "        \n",
    "        if color_i in conf_j:\n",
    "            dist = dist + 1\n",
    "            \n",
    "        if color_j in conf_i:\n",
    "            dist = dist + 1\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "def distance_user_embedding(i, j, ups, data):\n",
    "    user_i = ups[i][1]\n",
    "    user_j = ups[j][1]\n",
    "    user_i_id = data['index'][user_i]\n",
    "    user_j_id = data['index'][user_j]\n",
    "    \n",
    "    return np.linalg.norm(data['emb'][user_i_id]-data['emb'][user_j_id])\n",
    "\n",
    "def distance_user_colors(i, j, ups, data):\n",
    "    user_i = ups[i][1]\n",
    "    user_j = ups[j][1]\n",
    "    user_i_id = data['index'][user_i]\n",
    "    user_j_id = data['index'][user_j]\n",
    "    \n",
    "    return (1.-data['emb'][user_i_id].todense() * data['emb'][user_j_id].todense().T)[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ../../signet/signet.py -l signet_id.txt -i signet.txt -o signet -d 40 -t 10 -s 200\n",
      "0_model.pkl\n",
      "1_model.pkl\n",
      "2_model.pkl\n",
      "3_model.pkl\n",
      "4_model.pkl\n",
      "5_model.pkl\n",
      "6_model.pkl\n",
      "7_model.pkl\n",
      "8_model.pkl\n",
      "9_model.pkl\n",
      "component_assignment_0_model.pkl\n",
      "component_assignment_1_model.pkl\n",
      "component_assignment_2_model.pkl\n",
      "component_assignment_3_model.pkl\n",
      "component_assignment_4_model.pkl\n",
      "component_assignment_5_model.pkl\n",
      "component_assignment_6_model.pkl\n",
      "component_assignment_7_model.pkl\n",
      "component_assignment_8_model.pkl\n",
      "reddit_place_project\n",
      "signet\n",
      "signet.tar.gz\n",
      "\n",
      "avg pos =  0.5930333206798355 , n =  110532\n",
      "avg neg =  1.7969096206277424 , n =  21269\n"
     ]
    }
   ],
   "source": [
    "conflicts = compute_update_conflicts(ups)\n",
    "durations = compute_update_durations(ups)\n",
    "user_color, user_index_color = compute_user_color(ups)\n",
    "\n",
    "#TODO: We are currently using 40 dimensions, we might need more\n",
    "# We also need to understand whether these other parameters matter.\n",
    "ndim=40\n",
    "threshold=10\n",
    "total_samples=200\n",
    "n_negatives=5\n",
    "n_iterations=10\n",
    "user_index, emb = embed_users(G, ups, ndim, threshold, total_samples, n_negatives, n_iterations)\n",
    "\n",
    "features = [{'name': \"different_color\", 'func': different_color, 'data': None}, \n",
    "    {'name': \"distance_space\",  'func': distance_space, 'data': None}, \n",
    "    {'name': \"distance_time\", 'func': distance_time, 'data': None}, \n",
    "    {'name': \"distance_duration\", 'func': distance_duration, 'data': durations}, \n",
    "    {'name': \"distance_color\", 'func': distance_color, 'data': conflicts},\n",
    "    {'name': \"distance_user_embedding\", 'func': distance_user_embedding, 'data': {'index': user_index, 'emb': emb}},\n",
    "    {'name': \"distance_user_colors\", 'func': distance_user_colors, 'data': {'index': user_index_color, 'emb': user_color}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open('features_10x10.pkl', 'wb')\n",
    "pickle.dump(features, pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open('features_10x10.pkl', 'rb')\n",
    "features = pickle.load(pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_edges_file_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0734f61c180c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# All edges that belong to the validation fold need to be excluded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_feat_label_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_edges_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'unique_edges_file_name' is not defined"
     ]
    }
   ],
   "source": [
    "locations = store_locations(\"../data/atlas_complete.json\")\n",
    "    \n",
    "# All edges that belong to the validation fold need to be excluded\n",
    "A, b = build_feat_label_data(G.unique_edges_file_name, ups, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gboost = GradientBoostingRegressor(random_state=1, n_estimators=25).fit(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = createNonlinearRegressionNeuralNet(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_edge_weights_multithread(G, ups, model_gboost, features, 5)\n",
    "G.sort_edges()\n",
    "\n",
    "\n",
    "\n",
    "comp_assign = region_segmentation(G, ups, kappa)\n",
    "regions, sizes = extract_regions(comp_assign)\n",
    "ground_truth = create_ground_truth(input_filename, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y, projects_to_remove=projects_to_remove)\n",
    "num_correct_counter, num_assignments_made, precision, recall, region_assignments = eval_function( locations, regions, ups, ground_truth, threshold=0.3, draw=False)\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_edge_weights_multithread(G, ups, model_nn, features, 5)\n",
    "G.sort_edges()\n",
    "\n",
    "\n",
    "\n",
    "comp_assign = region_segmentation(G, ups, kappa)\n",
    "regions, sizes = extract_regions(comp_assign)\n",
    "ground_truth = create_ground_truth(input_filename, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y, projects_to_remove=projects_to_remove)\n",
    "num_correct_counter, num_assignments_made, precision, recall, region_assignments = eval_function( locations, regions, ups, ground_truth, threshold=0.3, draw=False)\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
