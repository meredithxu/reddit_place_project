{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOS:\n",
    "\n",
    "1) Think about new features\n",
    "2) Setup experiments on salinas\n",
    "3) 10-fold cross validation\n",
    "4) Compute \"compatibility\" between regions for future superpixel clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import scipy\n",
    "import networkx as nx\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "import operator\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../Python_code\") # go to parent dir\n",
    "from canvas_vis import * \n",
    "from analytics_combined import *\n",
    "from generate_proj_to_remove import *\n",
    "from project_data_analysis import *\n",
    "from user_embedding import *\n",
    "from segmentation import *\n",
    "from evaluation import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the size of the canvas that is being looked at\n",
    "min_x = 0\n",
    "max_x = 1002\n",
    "min_y = 0\n",
    "max_y = 1002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_to_remove = get_list_of_removed_proj(output_filename = \"../data/proj_to_remove.txt\")\n",
    "\n",
    "input_file= \"../data/sorted_tile_placements_proj.csv\"\n",
    "js_filename = \"../data/atlas_complete.json\"\n",
    "\n",
    "names, descriptions = read_picture_names_and_descriptions(js_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num edges =  525656443\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO: How far two vertices should be to be connected (1-4)?\n",
    "G, ups = create_graph(input_file, projects_to_remove, 4, min_x, max_x, min_y, max_y)\n",
    "\n",
    "print(\"num edges = \", G.n_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open('graph.pkl', 'wb')\n",
    "pickle.dump(G, pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open('ups.pkl', 'wb')\n",
    "pickle.dump(ups, pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open('graph.pkl', 'rb')\n",
    "G = pickle.load(pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open('ups.pkl', 'rb')\n",
    "ups = pickle.load(pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining 7 edge features and computing the information they require\n",
    "#Adding a new feature without changing the rest of the code should\n",
    "#be easy.\n",
    "#TODO: Are there other features that would improve the segmentation?\n",
    "#TODO: How many dimensions we need?\n",
    "\n",
    "def different_color(i, j, ups, data=None):\n",
    "    if ups[i][4] == ups[j][4]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "        \n",
    "def distance_space(i, j, ups, data=None):\n",
    "    xi = ups[i][2]\n",
    "    yi = ups[i][3]\n",
    "    xj = ups[j][2]\n",
    "    yj = ups[j][3]\n",
    "    \n",
    "    return np.sqrt(pow(xi-xj,2)+pow(yi-yj,2))\n",
    "\n",
    "def distance_time(i, j, ups, data=None):\n",
    "    time_i = ups[i][0]\n",
    "    time_j = ups[j][0]\n",
    "    \n",
    "    return np.sqrt(pow(time_i-time_j,2))\n",
    "\n",
    "def distance_duration(i, j, ups, durations):\n",
    "    return dist_duration(durations[i], durations[j])\n",
    "\n",
    "def distance_color(i, j, ups, conflicts):\n",
    "    color_i = ups[i][4]\n",
    "    color_j = ups[j][4]\n",
    "    \n",
    "    if color_i == color_j:\n",
    "        return 0\n",
    "    else:\n",
    "        max_up = len(ups)\n",
    "        dist = 0\n",
    "        \n",
    "        conf_i = []\n",
    "        if conflicts[i][0] <= max_up:\n",
    "            conf_i.append(ups[conflicts[i][0]][4])\n",
    "            \n",
    "        if conflicts[i][1] <= max_up:\n",
    "            conf_i.append(ups[conflicts[i][1]][4])\n",
    "        \n",
    "        conf_j = []\n",
    "        if conflicts[j][0] <= max_up:\n",
    "            conf_j.append(ups[conflicts[j][0]][4])\n",
    "            \n",
    "        if conflicts[j][1] <= max_up:\n",
    "            conf_j.append(ups[conflicts[j][1]][4])\n",
    "        \n",
    "        if color_i in conf_j:\n",
    "            dist = dist + 1\n",
    "            \n",
    "        if color_j in conf_i:\n",
    "            dist = dist + 1\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "def distance_user_embedding(i, j, ups, data):\n",
    "    user_i = ups[i][1]\n",
    "    user_j = ups[j][1]\n",
    "    user_i_id = data['index'][user_i]\n",
    "    user_j_id = data['index'][user_j]\n",
    "    \n",
    "    return np.linalg.norm(data['emb'][user_i_id]-data['emb'][user_j_id])\n",
    "\n",
    "def distance_user_colors(i, j, ups, data):\n",
    "    user_i = ups[i][1]\n",
    "    user_j = ups[j][1]\n",
    "    user_i_id = data['index'][user_i]\n",
    "    user_j_id = data['index'][user_j]\n",
    "    \n",
    "    return (1.-data['emb'][user_i_id].todense() * data['emb'][user_j_id].todense().T)[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ../../signet/signet.py -l signet_id.txt -i signet.txt -o signet -d 40 -t 10 -s 200\n",
      "reddit_place_project\n",
      "signet\n",
      "signet.tar.gz\n",
      "\n",
      "avg pos =  0.3015506132026709 , n =  99078239\n",
      "avg neg =  0.5931958323826662 , n =  8817972\n"
     ]
    }
   ],
   "source": [
    "conflicts = compute_update_conflicts(ups)\n",
    "durations = compute_update_durations(ups)\n",
    "user_color, user_index_color = compute_user_color(ups)\n",
    "\n",
    "#TODO: We are currently using 40 dimensions, we might need more\n",
    "# We also need to understand whether these other parameters matter.\n",
    "ndim=40\n",
    "threshold=10\n",
    "total_samples=200\n",
    "n_negatives=5\n",
    "n_iterations=10\n",
    "user_index, emb = embed_users(G, ups, ndim, threshold, total_samples, n_negatives, n_iterations)\n",
    "\n",
    "features = [{'name': \"different_color\", 'func': different_color, 'data': None}, \n",
    "    {'name': \"distance_space\",  'func': distance_space, 'data': None}, \n",
    "    {'name': \"distance_time\", 'func': distance_time, 'data': None}, \n",
    "    {'name': \"distance_duration\", 'func': distance_duration, 'data': durations}, \n",
    "    {'name': \"distance_color\", 'func': distance_color, 'data': conflicts},\n",
    "    {'name': \"distance_user_embedding\", 'func': distance_user_embedding, 'data': {'index': user_index, 'emb': emb}},\n",
    "    {'name': \"distance_user_colors\", 'func': distance_user_colors, 'data': {'index': user_index_color, 'emb': user_color}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open('features.pkl', 'wb')\n",
    "pickle.dump(features, pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open('features.pkl', 'rb')\n",
    "features = pickle.load(pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1155655, 40)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg pos =  0.7396222798030327 , n =  2041118\n",
      "avg neg =  1.6404971017330785 , n =  157029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7396222798030327, 1.6404971017330785)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_distances_pos_neg(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python ../../signet/signet.py -l signet_id.txt -i signet.txt -o signet -d 40 -t 5 -s 100\n",
    "avg pos =  1.1807355951313214 , n =  99078239\n",
    "avg neg =  1.3348554803394002 , n =  8817972\n",
    "\n",
    "python ../../signet/signet.py -l signet_id.txt -i signet.txt -o signet -d 80 -t 5 -s 100\n",
    "avg pos =  1.1750889637369661 , n =  99078239\n",
    "avg neg =  1.331160714429541 , n =  8817972\n",
    "\n",
    "python ../../signet/signet.py -l signet_id.txt -i signet.txt -o signet -d 40 -t 5 -s 150\n",
    "avg pos =  0.5868004540189559 , n =  99078239\n",
    "avg neg =  0.8949797397524855 , n =  8817972\n",
    "\n",
    "os.system(\"python ../../signet/signet.py -l signet_id.txt -i signet.txt -o signet -d 40 -t 5 -s 200\")\n",
    "\n",
    "avg pos =  0.30873725836758875 , n =  99078239\n",
    "avg neg =  0.60138161298838 , n =  8817972\n",
    "\n",
    "os.system(\"python ../../signet/signet.py -l signet_id.txt -i signet.txt -o signet -d 40 -t 5 -s 300\")\n",
    "\n",
    "avg pos =  0.28452876787163384 , n =  99078239\n",
    "avg neg =  0.57960637526801 , n =  8817972\n",
    "\n",
    "os.system(\"python ../../signet/signet.py -l signet_id.txt -i signet.txt -o signet -d 80 -t 5 -s 300\")\n",
    "\n",
    "avg pos =  0.25392424705396205 , n =  99078239\n",
    "avg neg =  0.5389355038583881 , n =  8817972\n",
    "\n",
    "os.system(\"python ../../signet/signet.py -l signet_id.txt -i signet.txt -o signet -d 100 -t 5 -s 300\")\n",
    "\n",
    "avg pos =  0.246320305975872 , n =  99078239\n",
    "avg neg =  0.529323314020317 , n =  8817972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=25,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=25,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=25,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=25,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=25,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=25,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=25,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=25,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=25,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=25,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "metric_vals = validate_best_model(evaluate, ups, G, features, input_file, projects_to_remove,'recall', min_x, min_y, max_x, max_y, load_models = True, load_segmentation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metric_vals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-10780f33c95c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AVG:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metric_vals' is not defined"
     ]
    }
   ],
   "source": [
    "print(metric_vals)\n",
    "print(\"AVG:\",(sum(metric_vals)/len(metric_vals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_best_model_wrapper(parameters):\n",
    "\n",
    "    vertex_lengths = parameters.get(\"v_lengths\")\n",
    "    projects_to_remove = parameters.get(\"projects_to_remove\")\n",
    "    input_filename = parameters.get(\"input_filename\")\n",
    "    min_x = parameters.get(\"min_x\")\n",
    "    max_x = parameters.get(\"max_x\")\n",
    "    min_y = parameters.get(\"min_y\")\n",
    "    max_y = parameters.get(\"max_y\")\n",
    "\n",
    "    n_dims = parameters.get(\"n_dims\")\n",
    "    thresholds = parameters.get(\"thresholds\")\n",
    "    total_samples = parameters.get(\"total_samples\")\n",
    "    n_negatives = parameters.get(\"n_negatives\")\n",
    "    n_iterations = parameters.get(\"n_iterations\")\n",
    "\n",
    "    kappa_vals = parameters[\"kappas\"]\n",
    "    validation_metrics = parameters(\"validation_metrics\")\n",
    "\n",
    "    best_score = -1\n",
    "    best_parameters = None\n",
    "\n",
    "    for v in vertex_lengths:\n",
    "        G, ups = create_graph(input_file, projects_to_remove,\n",
    "                              v, min_x, max_x, min_y, max_y)\n",
    "\n",
    "        for ndim in n_dims:\n",
    "            for threshold in thresholds:\n",
    "                for total_sample in total_samples:\n",
    "                    for n_negative in n_negatives:\n",
    "                        for n_iteration in n_iterations:\n",
    "                            user_index, emb = embed_users(G, ups, ndim, threshold, total_samples, n_negatives, n_iterations)\n",
    "\n",
    "                            features = [{'name': \"different_color\", 'func': different_color, 'data': None},\n",
    "                                        {'name': \"distance_space\",\n",
    "                                            'func': distance_space, 'data': None},\n",
    "                                        {'name': \"distance_time\",\n",
    "                                            'func': distance_time, 'data': None},\n",
    "                                        {'name': \"distance_duration\",\n",
    "                                         'func': distance_duration, 'data': durations},\n",
    "                                        {'name': \"distance_color\",\n",
    "                                         'func': distance_color, 'data': conflicts},\n",
    "                                        {'name': \"distance_user_embedding\", 'func': distance_user_embedding, 'data': {\n",
    "                                            'index': user_index, 'emb': emb}},\n",
    "                                        {'name': \"distance_user_colors\", 'func': distance_user_colors, 'data': {'index': user_index_color, 'emb': user_color}}]\n",
    "\n",
    "\n",
    "\n",
    "                            \n",
    "\n",
    "                            for kappa in kappa_vals:\n",
    "                                for metric in validation_metrics:\n",
    "                                    metric_vals = validate_best_model(evaluate, ups, G, features, input_file, projects_to_remove, metric, min_x, min_y, max_x, max_y)\n",
    "\n",
    "                                    avg_score = sum(metric_vals) / len(metric_vals)\n",
    "                                    if avg_score > best_score:\n",
    "                                        best_score = avg_score\n",
    "                                        best_parameters = { \n",
    "                                            \"v_length\": v, \n",
    "                                            \"ndim\" : ndim, \n",
    "                                            \"threshold\": threshold, \n",
    "                                            \"total_sample\":total_sample, \n",
    "                                            \"n_negative\" : n_negative,\n",
    "                                            \"n_iteration\" : n_iteration,\n",
    "                                            \"kappa\" : kappa,\n",
    "                                            \"metric\" : metric,\n",
    "                                            \"avg_score\" : avg_scores\n",
    "                                            }\n",
    "\n",
    "    return best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_parameters = {\n",
    "    \"v_lengths\" : [1,2,3,4],\n",
    "    \"projects_to_remove\" : projects_to_remove,\n",
    "    \"input_filename\" : input_filename,\n",
    "    \"min_x\" : min_x,\n",
    "    \"max_x\" : max_x,\n",
    "    \"min_y\" : min_y,\n",
    "    \"max_y\" : max_y,\n",
    "    \"n_dims\" : [40],\n",
    "    \"thresholds\" : [10],\n",
    "    \"total_samples\" : [200],\n",
    "    \"n_negatives\" : [5],\n",
    "    \"n_iterations\" : [10],\n",
    "    \"kappas\" : [0.25],\n",
    "    \"validation_metrics\" : ['recall']\n",
    "}\n",
    "best_model = validate_best_model_wrapper(validation_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# A,b = build_feat_label_data(G, ups, features)\n",
    "# model = GradientBoostingRegressor(random_state=1, n_estimators=25).fit(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open('model.pkl', 'wb')\n",
    "pickle.dump(model, pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open('model.pkl', 'rb')\n",
    "model = pickle.load(pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature statistics\n",
    "\n",
    "def feature_weight_statistics(G, ups, model, features, projects=None, regions=None):\n",
    "    '''\n",
    "    '''\n",
    "    statistics = {}\n",
    "    \n",
    "    region_check = {}\n",
    "    \n",
    "    if regions != None:\n",
    "        for r in regions:\n",
    "            for u in r:\n",
    "                region_check[u] = 1\n",
    "    \n",
    "    for f in range(len(features)):\n",
    "        #avg, min, max weights\n",
    "        sum_weights_in = 0\n",
    "        min_weight_in = 1e10\n",
    "        max_weight_in = 0\n",
    "    \n",
    "        sum_weights_out = 0\n",
    "        min_weight_out = 1e10\n",
    "        max_weight_out = 0\n",
    "        n_in = 0\n",
    "        n_out = 0\n",
    "    \n",
    "        with open(G.unique_edges_file_name, 'r') as file_in:\n",
    "            reader = csv.reader(file_in)\n",
    "    \n",
    "            for r in reader:\n",
    "                u = int(r[0])\n",
    "                v = int(r[1])\n",
    "                proj_u = ups[u][5]\n",
    "                proj_v = ups[v][5]\n",
    "                pixel_u = int(ups[u][6])\n",
    "                pixel_v = int(ups[v][6])\n",
    "                \n",
    "                w = features[f]['func'](u, v, ups, features[f]['data'])\n",
    "                \n",
    "                if pixel_u == 1 and pixel_v == 1 and regions is None or (u in region_check and v in region_check):\n",
    "                    if projects is None or (proj_u in projects and proj_v in projects):\n",
    "                        if proj_u == proj_v:\n",
    "                            sum_weights_in = sum_weights_in + w\n",
    "                            n_in = n_in + 1\n",
    "            \n",
    "                            if w < min_weight_in:\n",
    "                                min_weight_in = w\n",
    "                \n",
    "                            if w > max_weight_in:\n",
    "                                max_weight_in = w\n",
    "                        else:\n",
    "                            sum_weights_out = sum_weights_out + w\n",
    "                            n_out = n_out + 1\n",
    "            \n",
    "                            if w < min_weight_out:\n",
    "                                min_weight_out = w\n",
    "                \n",
    "                            if w > max_weight_out:\n",
    "                                max_weight_out = w                \n",
    "                \n",
    "        statistics[features[f]['name']] = {}\n",
    "        \n",
    "        statistics[features[f]['name']]['inside avg'] = sum_weights_in / n_in\n",
    "        statistics[features[f]['name']]['inside min'] = min_weight_in\n",
    "        statistics[features[f]['name']]['inside max'] = max_weight_in\n",
    "        statistics[features[f]['name']]['inside count'] =  n_in\n",
    "    \n",
    "        statistics[features[f]['name']]['outside avg'] = sum_weights_out / n_out\n",
    "        statistics[features[f]['name']]['outside min'] = min_weight_out\n",
    "        statistics[features[f]['name']]['outside max'] = max_weight_out\n",
    "        statistics[features[f]['name']]['outside count'] =  n_out\n",
    "    \n",
    "        statistics[features[f]['name']]['all avg'] = (sum_weights_in+sum_weights_out) / (n_in + n_out)\n",
    "        statistics[features[f]['name']]['all min'] = min(min_weight_in, min_weight_out)\n",
    "        statistics[features[f]['name']]['all max'] = max(max_weight_in, max_weight_out)\n",
    "        statistics[features[f]['name']]['all count'] =  n_in + n_out\n",
    "        \n",
    "        \n",
    "    sum_weights_in = 0\n",
    "    min_weight_in = 1e10\n",
    "    max_weight_in = 0\n",
    "    \n",
    "    sum_weights_out = 0\n",
    "    min_weight_out = 1e10\n",
    "    max_weight_out = 0\n",
    "    n_in = 0\n",
    "    n_out = 0\n",
    "    \n",
    "    with open(G.unique_edges_file_name, 'r') as file_in:\n",
    "        reader = csv.reader(file_in)\n",
    "    \n",
    "        for r in reader:\n",
    "            u = int(r[0])\n",
    "            v = int(r[1])\n",
    "            proj_u = ups[u][5]\n",
    "            proj_v = ups[v][5]\n",
    "            pixel_u = int(ups[u][6])\n",
    "            pixel_v = int(ups[v][6])\n",
    "                \n",
    "            w = compute_weight(int(u), int(v), ups, model, features)\n",
    "                \n",
    "            if pixel_u == 1 and pixel_v == 1 and regions is None or (u in region_check and v in region_check):\n",
    "                if projects is None or (proj_u in projects and proj_v in projects):\n",
    "                    if proj_u == proj_v:\n",
    "                        sum_weights_in = sum_weights_in + w\n",
    "                        n_in = n_in + 1\n",
    "            \n",
    "                        if w < min_weight_in:\n",
    "                            min_weight_in = w\n",
    "                \n",
    "                        if w > max_weight_in:\n",
    "                            max_weight_in = w\n",
    "                    else:\n",
    "                        sum_weights_out = sum_weights_out + w\n",
    "                        n_out = n_out + 1\n",
    "            \n",
    "                        if w < min_weight_out:\n",
    "                            min_weight_out = w\n",
    "                \n",
    "                        if w > max_weight_out:\n",
    "                            max_weight_out = w                \n",
    "                \n",
    "    statistics['weight'] = {}\n",
    "        \n",
    "    statistics['weight']['inside avg'] = sum_weights_in / n_in\n",
    "    statistics['weight']['inside min'] = min_weight_in\n",
    "    statistics['weight']['inside max'] = max_weight_in\n",
    "    statistics['weight']['inside count'] =  n_in\n",
    "    \n",
    "    statistics['weight']['outside avg'] = sum_weights_out / n_out\n",
    "    statistics['weight']['outside min'] = min_weight_out\n",
    "    statistics['weight']['outside max'] = max_weight_out\n",
    "    statistics['weight']['outside count'] =  n_out\n",
    "    \n",
    "    statistics['weight']['all avg'] = (sum_weights_in+sum_weights_out) / (n_in + n_out)\n",
    "    statistics['weight']['all min'] = min(min_weight_in, min_weight_out)\n",
    "    statistics['weight']['all max'] = max(max_weight_in, max_weight_out)\n",
    "    statistics['weight']['all count'] =  n_in + n_out\n",
    "    \n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'different_color': {'all avg': 0.5506835397020043,\n",
       "  'all count': 2948768,\n",
       "  'all max': 1,\n",
       "  'all min': 0,\n",
       "  'inside avg': 0.49820972518183027,\n",
       "  'inside count': 2435101,\n",
       "  'inside max': 1,\n",
       "  'inside min': 0,\n",
       "  'outside avg': 0.7994420509785523,\n",
       "  'outside count': 513667,\n",
       "  'outside max': 1,\n",
       "  'outside min': 0},\n",
       " 'distance_color': {'all avg': 0.20388277409413016,\n",
       "  'all count': 2948768,\n",
       "  'all max': 2,\n",
       "  'all min': 0,\n",
       "  'inside avg': 0.1897297073098816,\n",
       "  'inside count': 2435101,\n",
       "  'inside max': 2,\n",
       "  'inside min': 0,\n",
       "  'outside avg': 0.27097711163068683,\n",
       "  'outside count': 513667,\n",
       "  'outside max': 2,\n",
       "  'outside min': 0},\n",
       " 'distance_duration': {'all avg': 0.4178737626877978,\n",
       "  'all count': 2948768,\n",
       "  'all max': 1.0,\n",
       "  'all min': 0.0,\n",
       "  'inside avg': 0.4081432360968296,\n",
       "  'inside count': 2435101,\n",
       "  'inside max': 1.0,\n",
       "  'inside min': 0.0,\n",
       "  'outside avg': 0.4640025095845095,\n",
       "  'outside count': 513667,\n",
       "  'outside max': 1.0,\n",
       "  'outside min': 0.0},\n",
       " 'distance_space': {'all avg': 3.4444024146336703,\n",
       "  'all count': 2948768,\n",
       "  'all max': 5.6568542494923806,\n",
       "  'all min': 1.0,\n",
       "  'inside avg': 3.3533549863444936,\n",
       "  'inside count': 2435101,\n",
       "  'inside max': 5.6568542494923806,\n",
       "  'inside min': 1.0,\n",
       "  'outside avg': 3.8760238418898529,\n",
       "  'outside count': 513667,\n",
       "  'outside max': 5.6568542494923806,\n",
       "  'outside min': 1.0},\n",
       " 'distance_time': {'all avg': 41780763.901398823,\n",
       "  'all count': 2948768,\n",
       "  'all max': 256942000.0,\n",
       "  'all min': 0.0,\n",
       "  'inside avg': 41172411.975519702,\n",
       "  'inside count': 2435101,\n",
       "  'inside max': 256942000.0,\n",
       "  'inside min': 0.0,\n",
       "  'outside avg': 44664730.329182133,\n",
       "  'outside count': 513667,\n",
       "  'outside max': 255141000.0,\n",
       "  'outside min': 0.0},\n",
       " 'distance_user_colors': {'all avg': 0.76494851215681059,\n",
       "  'all count': 2948768,\n",
       "  'all max': 2.0,\n",
       "  'all min': -4.4408920985006262e-16,\n",
       "  'inside avg': 0.73644122004453416,\n",
       "  'inside count': 2435101,\n",
       "  'inside max': 2.0,\n",
       "  'inside min': -4.4408920985006262e-16,\n",
       "  'outside avg': 0.90009080381638107,\n",
       "  'outside count': 513667,\n",
       "  'outside max': 2.0,\n",
       "  'outside min': -4.4408920985006262e-16},\n",
       " 'distance_user_embedding': {'all avg': 0.86226089843750753,\n",
       "  'all count': 2948768,\n",
       "  'all max': 1.9995698268581059,\n",
       "  'all min': 0.0,\n",
       "  'inside avg': 0.85975792729527578,\n",
       "  'inside count': 2435101,\n",
       "  'inside max': 1.9995698268581059,\n",
       "  'inside min': 0.0,\n",
       "  'outside avg': 0.87412653810565788,\n",
       "  'outside count': 513667,\n",
       "  'outside max': 1.9991619114213428,\n",
       "  'outside min': 0.0},\n",
       " 'weight': {'all avg': 0.17419715623612403,\n",
       "  'all count': 2948768,\n",
       "  'all max': 0.35335466992619724,\n",
       "  'all min': 0.024772166821316843,\n",
       "  'inside avg': 0.16141546227732376,\n",
       "  'inside count': 2435101,\n",
       "  'inside max': 0.35335466992619724,\n",
       "  'inside min': 0.024772166821316843,\n",
       "  'outside avg': 0.23479033380207348,\n",
       "  'outside count': 513667,\n",
       "  'outside max': 0.35335466992619724,\n",
       "  'outside min': 0.024772166821316843}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_weight_statistics(G, ups, model, features, projects=None, regions=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature:  different_color 0.6011497753202893\n",
      "feature:  distance_space 0.17206012211539523\n",
      "feature:  distance_time 0.0865242392379522\n",
      "feature:  distance_duration 0.00021950883112781502\n",
      "feature:  distance_color 0.00747805169393991\n",
      "feature:  distance_user_embedding 0.0964976420028267\n",
      "feature:  distance_user_colors 0.03607066079846882\n"
     ]
    }
   ],
   "source": [
    "#Feature importances\n",
    "\n",
    "for f in range(len(features)):\n",
    "    print(\"feature: \", features[f]['name'], model.feature_importances_[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_edge_weights_multithread(G, ups, model, features, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def compute_weight_wrapper(param):\n",
    "    '''\n",
    "        Simple wrapper for the compute_weight function\n",
    "    '''    \n",
    "    #Loading pickled features\n",
    "    pfile = open('features.pkl', 'rb')\n",
    "    features = pickle.load(pfile)\n",
    "    pfile.close()\n",
    "\n",
    "    return compute_weight(param[0], param[1], param[2], features)\n",
    "\n",
    "def compute_weight_multithread(edge_buffer, ups, model, n_threads):\n",
    "    '''\n",
    "        Computes weights for set of edges in edge_buffer using multithreading\n",
    "    '''\n",
    "\n",
    "    #Dividing the work\n",
    "    edges_per_thread = int(len(edge_buffer) / n_threads)\n",
    "\n",
    "    edge_parts = []\n",
    "    for t in range(n_threads):\n",
    "        edge_parts.append([])\n",
    "\n",
    "    e = 0\n",
    "    for e in range(len(edge_buffer)):\n",
    "        t = e % n_threads\n",
    "        edge_parts[t].append(edge_buffer[e])\n",
    "\n",
    "    futures = []\n",
    "\n",
    "    #Multithreading\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=n_threads) as executor:\n",
    "        for t in range(n_threads):\n",
    "            fut = executor.submit(compute_weight_wrapper, (edge_parts[t], ups, model))\n",
    "            futures.append(fut)\n",
    "\n",
    "    W = np.zeros(len(edge_buffer))\n",
    "\n",
    "    for t in range(n_threads):\n",
    "        fut = futures[t]\n",
    "        res = fut.result()\n",
    "        for e in range(res.shape[0]):\n",
    "            W[e*n_threads+t] = res[e]\n",
    "\n",
    "    return W\n",
    "\n",
    "def compute_edge_weights_multithread(G, ups, model, features, n_threads):\n",
    "    '''\n",
    "        Computes weights for edges in the graph using multithreading.\n",
    "    '''\n",
    "\n",
    "    if os.path.exists(G.edges_file_name):\n",
    "        os.remove(G.edges_file_name)\n",
    "    \n",
    "    #Pickling feature data\n",
    "    pfile = open('features.pkl', 'wb')\n",
    "    pickle.dump(features, pfile)\n",
    "    pfile.close()\n",
    "        \n",
    "    edge_buffer = []\n",
    "\n",
    "    with open(G.unique_edges_file_name, 'r') as file_in:\n",
    "        reader = csv.reader(file_in)\n",
    "\n",
    "        for r in reader:\n",
    "            u = r[0]\n",
    "            v = r[1]\n",
    "            lb = r[2]\n",
    "            type_edge = int(r[3])\n",
    "\n",
    "            if type_edge > 0:\n",
    "                edge_buffer.append((int(u), int(v), lb, type_edge))\n",
    "\n",
    "                if len(edge_buffer) >= G.buffer_size:\n",
    "\n",
    "                    W = compute_weight_multithread(edge_buffer, ups, model, n_threads)\n",
    "\n",
    "                    for e in range(len(edge_buffer)):\n",
    "                        u = edge_buffer[e][0]\n",
    "                        v = edge_buffer[e][1]\n",
    "                        lb = edge_buffer[e][2]\n",
    "                        type_edge = edge_buffer[e][3]\n",
    "                        w = W[e]\n",
    "\n",
    "                        G.set_weight(u, v, lb, type_edge, w)\n",
    "\n",
    "                    edge_buffer = []\n",
    "\n",
    "    if len(edge_buffer) > 0:\n",
    "        W = compute_weight_multithread(edge_buffer, ups, model, features, n_threads)\n",
    "\n",
    "        for e in range(len(edge_buffer)):\n",
    "            u = edge_buffer[e][0]\n",
    "            v = edge_buffer[e][1]\n",
    "            lb = edge_buffer[e][2]\n",
    "            type_edge = edge_buffer[e][3]\n",
    "            w = W[e]\n",
    "\n",
    "            G.set_weight(u, v, lb, type_edge, w)\n",
    "\n",
    "    G.flush_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running process:  45252\n",
      "Running process:  45259\n",
      "Running process:  45269\n",
      "Running process:  45273\n",
      "Running process:  45276\n",
      "Running process:  4083\n",
      "Running process:  4085\n",
      "Running process:  4086\n",
      "Running process:  4088\n",
      "Running process:  4089\n",
      "Running process:  8106\n",
      "Running process:  8109\n",
      "Running process:  8111\n",
      "Running process:  8114\n",
      "Running process:  8116\n",
      "Running process:  12167\n",
      "Running process:  12170\n",
      "Running process:  12173\n",
      "Running process:  12175\n",
      "Running process:  12178\n",
      "Running process:  16390\n",
      "Running process:  16393\n",
      "Running process:  16395\n",
      "Running process:  16397\n",
      "Running process:  16401\n",
      "Running process:  20770\n",
      "Running process:  20773\n",
      "Running process:  20776\n",
      "Running process:  20778\n",
      "Running process:  20781\n",
      "Running process:  25013\n",
      "Running process:  25015\n",
      "Running process:  25018\n",
      "Running process:  25021\n",
      "Running process:  25024\n",
      "Running process:  29737\n",
      "Running process:  29740\n",
      "Running process:  29742\n",
      "Running process:  29745\n",
      "Running process:  29747\n",
      "Running process:  34488\n",
      "Running process:  34491\n",
      "Running process:  34493\n",
      "Running process:  34498\n",
      "Running process:  34500\n",
      "Running process:  39210\n",
      "Running process:  39213\n",
      "Running process:  39215\n",
      "Running process:  39219\n",
      "Running process:  39221\n",
      "Running process:  44202\n",
      "Running process:  44204\n",
      "Running process:  44208\n",
      "Running process:  44210\n",
      "Running process:  44213\n",
      "Running process:  48909\n",
      "Running process:  48912\n",
      "Running process:  48914\n",
      "Running process:  48917\n",
      "Running process:  48919\n",
      "Running process:  5168\n",
      "Running process:  5170\n",
      "Running process:  5173\n",
      "Running process:  5176\n",
      "Running process:  5179\n",
      "Running process:  9011\n",
      "Running process:  9014\n",
      "Running process:  9016\n",
      "Running process:  9017\n",
      "Running process:  9019\n",
      "Running process:  12658\n",
      "Running process:  12661\n",
      "Running process:  12663\n",
      "Running process:  12666\n",
      "Running process:  12668\n",
      "Running process:  16978\n",
      "Running process:  16981\n",
      "Running process:  16983\n",
      "Running process:  16987\n",
      "Running process:  16989\n",
      "Running process:  21477\n",
      "Running process:  21480\n",
      "Running process:  21483\n",
      "Running process:  21485\n",
      "Running process:  21488\n",
      "Running process:  24114\n",
      "Running process:  24116\n",
      "Running process:  24117\n",
      "Running process:  24119\n",
      "Running process:  24120\n",
      "Running process:  25832\n",
      "Running process:  25833\n",
      "Running process:  25835\n",
      "Running process:  25836\n",
      "Running process:  25838\n",
      "Running process:  27760\n",
      "Running process:  27761\n",
      "Running process:  27763\n",
      "Running process:  27764\n",
      "Running process:  27766\n",
      "Running process:  29555\n",
      "Running process:  29557\n",
      "Running process:  30996\n",
      "Running process:  30997\n",
      "Running process:  30999\n",
      "Running process:  31000\n",
      "Running process:  31001\n",
      "Running process:  32498\n",
      "Running process:  32500\n",
      "Running process:  32501\n",
      "Running process:  32503\n",
      "Running process:  32504\n",
      "Running process:  33958\n",
      "Running process:  33959\n",
      "Running process:  33961\n",
      "Running process:  33962\n",
      "Running process:  33964\n",
      "Running process:  35446\n",
      "Running process:  35448\n",
      "Running process:  35449\n",
      "Running process:  35451\n",
      "Running process:  35452\n",
      "Running process:  36895\n",
      "Running process:  36897\n",
      "Running process:  36899\n",
      "Running process:  36900\n",
      "Running process:  36902\n",
      "Running process:  38438\n",
      "Running process:  38440\n",
      "Running process:  38441\n",
      "Running process:  38442\n",
      "Running process:  38444\n",
      "Running process:  39862\n",
      "Running process:  39864\n",
      "Running process:  39865\n",
      "Running process:  39867\n",
      "Running process:  39868\n",
      "Running process:  41375\n",
      "Running process:  41376\n",
      "Running process:  41378\n",
      "Running process:  41380\n",
      "Running process:  41382\n",
      "Running process:  42909\n",
      "Running process:  42911\n",
      "Running process:  42912\n",
      "Running process:  42914\n",
      "Running process:  42915\n",
      "Running process:  44369\n",
      "Running process:  44370\n",
      "Running process:  44372\n",
      "Running process:  44373\n",
      "Running process:  44375\n",
      "Running process:  45810\n",
      "Running process:  45812\n",
      "Running process:  45813\n",
      "Running process:  45815\n",
      "Running process:  45816\n",
      "Running process:  47219\n",
      "Running process:  47221\n",
      "Running process:  47222\n",
      "Running process:  47225\n",
      "Running process:  47226\n",
      "Running process:  48661\n",
      "Running process:  48663\n",
      "Running process:  48664\n",
      "Running process:  48666\n",
      "Running process:  48667\n",
      "Running process:  1300\n",
      "Running process:  1301\n",
      "Running process:  1302\n",
      "Running process:  1304\n",
      "Running process:  1305\n",
      "Running process:  2813\n",
      "Running process:  2815\n",
      "Running process:  2816\n",
      "Running process:  2818\n",
      "Running process:  2819\n",
      "Running process:  4323\n",
      "Running process:  4325\n",
      "Running process:  4327\n",
      "Running process:  4328\n",
      "Running process:  4330\n",
      "Running process:  5829\n",
      "Running process:  5831\n",
      "Running process:  5832\n",
      "Running process:  5834\n",
      "Running process:  5835\n",
      "Running process:  7303\n",
      "Running process:  7305\n",
      "Running process:  7306\n",
      "Running process:  7308\n",
      "Running process:  7309\n",
      "Running process:  8792\n",
      "Running process:  8793\n",
      "Running process:  8795\n",
      "Running process:  8796\n",
      "Running process:  8798\n",
      "Running process:  10228\n",
      "Running process:  10229\n",
      "Running process:  10230\n",
      "Running process:  10232\n",
      "Running process:  10233\n",
      "Running process:  11721\n",
      "Running process:  11723\n",
      "Running process:  11724\n",
      "Running process:  11726\n",
      "Running process:  11727\n",
      "Running process:  13193\n",
      "Running process:  13194\n",
      "Running process:  13196\n",
      "Running process:  13197\n",
      "Running process:  13199\n",
      "Running process:  14770\n",
      "Running process:  14772\n",
      "Running process:  14773\n",
      "Running process:  14775\n",
      "Running process:  14776\n",
      "Running process:  16332\n",
      "Running process:  16334\n",
      "Running process:  16335\n",
      "Running process:  16336\n",
      "Running process:  16338\n",
      "Running process:  18151\n",
      "Running process:  18152\n",
      "Running process:  18155\n",
      "Running process:  18156\n",
      "Running process:  18158\n",
      "Running process:  19861\n",
      "Running process:  19862\n",
      "Running process:  19864\n",
      "Running process:  19865\n",
      "Running process:  19867\n",
      "Running process:  21434\n",
      "Running process:  21436\n",
      "Running process:  21437\n",
      "Running process:  21438\n",
      "Running process:  21440\n",
      "Running process:  23046\n",
      "Running process:  23047\n",
      "Running process:  23048\n",
      "Running process:  23050\n",
      "Running process:  23051\n",
      "Running process:  24598\n",
      "Running process:  24600\n",
      "Running process:  24601\n",
      "Running process:  24603\n",
      "Running process:  24604\n",
      "Running process:  26177\n",
      "Running process:  26178\n",
      "Running process:  26180\n",
      "Running process:  26181\n",
      "Running process:  26183\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "compute_weight_multithread() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3fc22d9db550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompute_edge_weights_multithread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-b2f6df4d8770>\u001b[0m in \u001b[0;36mcompute_edge_weights_multithread\u001b[0;34m(G, ups, model, features, n_threads)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_weight_multithread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_weight_multithread() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "compute_edge_weights_multithread(G, ups, model, features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.sort_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num regions =  1699614  max size region =  17405\n"
     ]
    }
   ],
   "source": [
    "comp_assign = region_segmentation(G, ups, .25)\n",
    "regions, sizes = extract_regions(comp_assign)\n",
    "\n",
    "print(\"num regions = \", len(regions), \" max size region = \", np.max(sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the percentage that each ground truth image overlaps with the region\n",
    "locations = store_locations(\"../data/atlas_complete.json\")\n",
    "ground_truth = create_ground_truth(input_file,0, sys.maxsize, min_x, max_x, min_y, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_statistics = compute_overlap_area(locations, regions[0], ups, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-96e89ba817df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'assign_pixels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-21c255e2020f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Keeping only final pixels from the regions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpixel_assign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_assign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpixel_regions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_assign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'assign_pixels' is not defined"
     ]
    }
   ],
   "source": [
    "#Keeping only final pixels from the regions\n",
    "\n",
    "pixel_assign = assign_pixels(comp_assign, ups)\n",
    "pixel_regions, pixel_sizes = extract_regions(pixel_assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_top_regions(pixel_regions, pixel_sizes, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_region(ups, extract_region(comp_assign, 1017523), \"../plots/region.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_filename = \"../data/atlas_complete.json\"\n",
    "\n",
    "names, descriptions = read_picture_names_and_descriptions(js_filename)\n",
    "\n",
    "\n",
    "def region_statistics(G, region, ups):\n",
    "    '''\n",
    "        Prints a few region statistics.\n",
    "    '''\n",
    "    #avg, min, max weights\n",
    "    sum_weights_in = 0\n",
    "    min_weight_in = 1e10\n",
    "    max_weight_in = 0\n",
    "    \n",
    "    sum_weights_out = 0\n",
    "    min_weight_out = 1e10\n",
    "    max_weight_out = 0\n",
    "    n_in = 0\n",
    "    n_out = 0\n",
    "    \n",
    "    n_edges = 0\n",
    "    region_check = {}\n",
    "    \n",
    "    for u in region:\n",
    "        region_check[u] = 1\n",
    "    \n",
    "    with open(G.sorted_edges_file_name, 'r') as file_in:\n",
    "        reader = csv.reader(file_in)\n",
    "    \n",
    "        for r in reader:\n",
    "            u = int(r[0])\n",
    "            v = int(r[1])\n",
    "            w = float(r[4])\n",
    "            \n",
    "            if u in region_check and v in region_check:\n",
    "                n_edges = n_edges + 1\n",
    "                sum_weights_in = sum_weights_in + w\n",
    "                n_in = n_in + 1\n",
    "            \n",
    "                if w < min_weight_in:\n",
    "                    min_weight_in = w\n",
    "                \n",
    "                if w > max_weight_in:\n",
    "                    max_weight_in = w\n",
    "                    \n",
    "            elif u in region_check or v in region_check:\n",
    "                sum_weights_out = sum_weights_out + w\n",
    "                n_out = n_out + 1\n",
    "            \n",
    "                if w < min_weight_out:\n",
    "                    min_weight_out = w\n",
    "                \n",
    "                if w > max_weight_out:\n",
    "                    max_weight_out = w\n",
    "    \n",
    "    color_dist = np.zeros(16)\n",
    "    n_pixel = 0\n",
    "    n_pixel_color = 0\n",
    "    min_time = sys.maxsize\n",
    "    max_time = 0\n",
    "    projs = {}\n",
    "    for u in region:\n",
    "        if ups[u][6] == 1:\n",
    "            n_pixel = n_pixel + 1\n",
    "            if ups[u][5] not in projs:\n",
    "                projs[ups[u][5]] = 0\n",
    "            \n",
    "            projs[ups[u][5]] = projs[ups[u][5]] + 1\n",
    "        if ups[u][7] == 1:\n",
    "            n_pixel_color = n_pixel_color + 1\n",
    "            \n",
    "        if ups[u][0] > max_time:\n",
    "            max_time = ups[u][0]\n",
    "            \n",
    "        if ups[u][0] < min_time:\n",
    "            min_time = ups[u][0]\n",
    "        \n",
    "        color_dist[int(ups[u][4])] = color_dist[int(ups[u][4])] + 1\n",
    "    \n",
    "    print(\"num updates = \", len(region))\n",
    "    print(\"num_edges = \", n_edges)\n",
    "    print(\"num pixels = \", n_pixel, \" (\", 100 * n_pixel / len(region), \"%)\")\n",
    "    print(\"num_pixel_colors = \", n_pixel_color, \" (\", 100 * n_pixel / len(region), \"%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    sorted_projs = sorted(projs.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    for i in range(len(sorted_projs)):\n",
    "        print(\"proj \", names[int(sorted_projs[i][0])], \" #final updates = \", sorted_projs[i][1], \" (\",\n",
    "              100 * sorted_projs[i][1] / n_pixel, \"% of final, \", 100 * sorted_projs[i][1] / len(region), \" of total)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print(\"colors: \", list(color_dist))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print(\"duration: \", min_time, \" - \", max_time, \" (\", (max_time-min_time)/ 1000, \" seconds)\")\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    print(\"avg weight inside = \",  sum_weights_in / n_in)\n",
    "    print (\"min weight inside = \", min_weight_in)\n",
    "    print(\"max weight inside = \", max_weight_in)\n",
    "    print(\"#edges inside = \", n_in)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print(\"avg weight outside = \",  sum_weights_out / n_out)\n",
    "    print (\"min weight outside = \", min_weight_out)\n",
    "    print(\"max weight outside = \", max_weight_out)\n",
    "    print(\"#edges outside = \", n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num updates =  3497\n",
      "num_edges =  34238\n",
      "num pixels =  333  ( 9.522447812410638 %)\n",
      "num_pixel_colors =  1647  ( 9.522447812410638 %)\n",
      "\n",
      "proj  Rickroll QR code  #final updates =  161  ( 48.348348348348345 % of final,  4.603946239633972  of total)\n",
      "proj  Meat Boy  #final updates =  145  ( 43.54354354354354 % of final,  4.146411209608235  of total)\n",
      "proj  RuneScape disconnected message  #final updates =  27  ( 8.108108108108109 % of final,  0.77209036316843  of total)\n",
      "\n",
      "colors:  [651.0, 3.0, 0.0, 2624.0, 5.0, 183.0, 3.0, 10.0, 9.0, 0.0, 5.0, 0.0, 0.0, 4.0, 0.0, 0.0]\n",
      "\n",
      "duration:  1491075060000  -  1491238585000  ( 163525.0  seconds)\n",
      "\n",
      "avg weight inside =  0.07799586747581512\n",
      "min weight inside =  0.0101650354992\n",
      "max weight inside =  0.609298714302\n",
      "#edges inside =  34238\n",
      "\n",
      "avg weight outside =  0.1759484575053703\n",
      "min weight outside =  0.012011047842\n",
      "max weight outside =  0.623526170427\n",
      "#edges outside =  195866\n"
     ]
    }
   ],
   "source": [
    "region_statistics(G, extract_region(comp_assign, 1017523), ups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_statistics(G, comp_assign, ups, proj):\n",
    "    '''\n",
    "        Prints a few region statistics.\n",
    "    '''\n",
    "    #avg, min, max weights\n",
    "    sum_weights_in = 0\n",
    "    min_weight_in = 1e10\n",
    "    max_weight_in = 0\n",
    "    \n",
    "    sum_weights_out = 0\n",
    "    min_weight_out = 1e10\n",
    "    max_weight_out = 0\n",
    "    n_in = 0\n",
    "    n_out = 0\n",
    "    \n",
    "    n_edges = 0\n",
    "    regions = {}\n",
    "    G_proj = nx.Graph()\n",
    "    \n",
    "    with open(G.sorted_edges_file_name, 'r') as file_in:\n",
    "        reader = csv.reader(file_in)\n",
    "    \n",
    "        for r in reader:\n",
    "            u = int(r[0])\n",
    "            v = int(r[1])\n",
    "            w = float(r[4])\n",
    "            \n",
    "            if ups[u][6] == 1 and ups[v][6] == 1:\n",
    "                if ups[u][5] == proj and ups[v][5] == proj:\n",
    "                    G_proj.add_edge(u,v)\n",
    "                    n_edges = n_edges + 1\n",
    "                    sum_weights_in = sum_weights_in + w\n",
    "                    n_in = n_in + 1\n",
    "\n",
    "                    if w < min_weight_in:\n",
    "                        min_weight_in = w\n",
    "\n",
    "                    if w > max_weight_in:\n",
    "                        max_weight_in = w\n",
    "\n",
    "            elif (ups[u][6] == 1 and ups[u][5] == proj) or (ups[u][6] == 1 and ups[v][5] == proj):\n",
    "                sum_weights_out = sum_weights_out + w\n",
    "                n_out = n_out + 1\n",
    "\n",
    "                if w < min_weight_out:\n",
    "                    min_weight_out = w\n",
    "\n",
    "                if w > max_weight_out:\n",
    "                    max_weight_out = w\n",
    "                    \n",
    "    size_proj = 0\n",
    "    for u in range(len(ups)):\n",
    "        if ups[u][6] == 1 and ups[u][5] == proj:\n",
    "            size_proj = size_proj + 1\n",
    "            if comp_assign[u] not in regions:\n",
    "                regions[comp_assign[u]] = 0\n",
    "                \n",
    "            regions[comp_assign[u]] = regions[comp_assign[u]] + 1\n",
    "            \n",
    "    region_sizes = {}\n",
    "    \n",
    "    for r in regions:\n",
    "        region_sizes[r] = 0\n",
    "        \n",
    "    for u in range(len(ups)):\n",
    "        if comp_assign[u] in regions and ups[u][6] == 1:\n",
    "            region_sizes[comp_assign[u]] = region_sizes[comp_assign[u]] + 1\n",
    "    \n",
    "    sorted_regions = sorted(regions.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    for i in range(len(sorted_regions)):\n",
    "        print(\"region \", sorted_regions[i][0], \" #updates = \", sorted_regions[i][1], \" (\",\n",
    "              100 * sorted_regions[i][1] / size_proj, \"% of project, \", \n",
    "              100 * sorted_regions[i][1] / region_sizes[sorted_regions[i][0]], \"% of region)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print(\"avg weight inside = \",  sum_weights_in / n_in)\n",
    "    print (\"min weight inside = \", min_weight_in)\n",
    "    print(\"max weight inside = \", max_weight_in)\n",
    "    print(\"#edges inside = \", n_in)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print(\"avg weight outside = \",  sum_weights_out / n_out)\n",
    "    print (\"min weight outside = \", min_weight_out)\n",
    "    print(\"max weight outside = \", max_weight_out)\n",
    "    print(\"#edges outside = \", n_out)\n",
    "    \n",
    "    print(\"Graph connected : \", nx.is_connected(G_proj))\n",
    "    print(\"Largest connected component: \", 100 * max(nx.connected_component_subgraphs(G_proj), key=len).number_of_nodes() / size_proj, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region  1017523  #updates =  145  ( 33.25688073394495 % of project,  43.54354354354354 % of region)\n",
      "region  889685  #updates =  142  ( 32.56880733944954 % of project,  94.03973509933775 % of region)\n",
      "region  992676  #updates =  68  ( 15.596330275229358 % of project,  31.48148148148148 % of region)\n",
      "region  1080977  #updates =  48  ( 11.009174311926605 % of project,  97.95918367346938 % of region)\n",
      "region  1020554  #updates =  7  ( 1.6055045871559632 % of project,  100.0 % of region)\n",
      "region  875891  #updates =  4  ( 0.9174311926605505 % of project,  100.0 % of region)\n",
      "region  1022053  #updates =  3  ( 0.6880733944954128 % of project,  100.0 % of region)\n",
      "region  960835  #updates =  2  ( 0.45871559633027525 % of project,  100.0 % of region)\n",
      "region  1046798  #updates =  2  ( 0.45871559633027525 % of project,  100.0 % of region)\n",
      "region  1029455  #updates =  2  ( 0.45871559633027525 % of project,  100.0 % of region)\n",
      "region  1090120  #updates =  2  ( 0.45871559633027525 % of project,  100.0 % of region)\n",
      "region  1071907  #updates =  2  ( 0.45871559633027525 % of project,  33.333333333333336 % of region)\n",
      "region  1079709  #updates =  2  ( 0.45871559633027525 % of project,  100.0 % of region)\n",
      "region  1083563  #updates =  2  ( 0.45871559633027525 % of project,  100.0 % of region)\n",
      "region  1015758  #updates =  1  ( 0.22935779816513763 % of project,  0.3389830508474576 % of region)\n",
      "region  996492  #updates =  1  ( 0.22935779816513763 % of project,  100.0 % of region)\n",
      "region  1110324  #updates =  1  ( 0.22935779816513763 % of project,  100.0 % of region)\n",
      "region  1115386  #updates =  1  ( 0.22935779816513763 % of project,  100.0 % of region)\n",
      "region  983452  #updates =  1  ( 0.22935779816513763 % of project,  100.0 % of region)\n",
      "\n",
      "avg weight inside =  0.11366581627239171\n",
      "min weight inside =  0.012011047842\n",
      "max weight inside =  0.555204290901\n",
      "#edges inside =  13435\n",
      "\n",
      "avg weight outside =  0.1766311659424988\n",
      "min weight outside =  0.0101650354992\n",
      "max weight outside =  0.623526170427\n",
      "#edges outside =  29895\n",
      "Graph connected :  True\n",
      "Largest connected component:  100.0 %\n"
     ]
    }
   ],
   "source": [
    " project_statistics(G, comp_assign, ups, '339')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_statistics(G, ups, projs):\n",
    "    '''\n",
    "        Computes weight statistics for the weights within \n",
    "        and across projects.\n",
    "    '''\n",
    "    \n",
    "    sum_in_final = 0\n",
    "    sum_out_final = 0\n",
    "    n_in_final = 0\n",
    "    n_out_final = 0\n",
    "    \n",
    "    \n",
    "    sum_in_color = 0\n",
    "    sum_out_color = 0\n",
    "    n_in_color = 0\n",
    "    n_out_color = 0\n",
    "    \n",
    "    with open(G.sorted_edges_file_name, 'r') as file_in:\n",
    "        reader = csv.reader(file_in)\n",
    "    \n",
    "        for r in reader:\n",
    "            u = int(r[0])\n",
    "            v = int(r[1])\n",
    "            w = float(r[4])\n",
    "            type_edge = int(r[3])\n",
    "            proj_u = ups[u][5]\n",
    "            proj_v = ups[v][5]\n",
    "            \n",
    "            if type_edge > 0:\n",
    "                if projs is None or (proj_u in projs and proj_v in projs):\n",
    "                    if ups[u][6] == 1 and ups[v][6] == 1:\n",
    "                        if ups[u][5] == ups[v][5]:\n",
    "                            sum_in_final = sum_in_final + w\n",
    "                            n_in_final = n_in_final + 1\n",
    "                        else:\n",
    "                            sum_out_final = sum_out_final + w\n",
    "                            n_out_final = n_out_final + 1\n",
    "\n",
    "                    if ups[u][7] == 1 and ups[v][7] == 1:\n",
    "                        if ups[u][5] == ups[v][5]:\n",
    "                            sum_in_color = sum_in_color + w\n",
    "                            n_in_color = n_in_color + 1\n",
    "                        else:\n",
    "                            sum_out_color = sum_out_color + w\n",
    "                            n_out_color = n_out_color + 1\n",
    "                            \n",
    "                    \n",
    "                    \n",
    "    print(\"avg weight inside projects (pixel) = \", sum_in_final / n_in_final)\n",
    "    print(\"avg weight outside projects (pixel) = \", sum_out_final / n_out_final)\n",
    "    print(\"avg weight (pixel) = \", (sum_in_final + sum_out_final) / (n_in_final + n_out_final) )\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print(\"avg weight inside projects (color) = \", sum_in_color / n_in_color)\n",
    "    print(\"avg weight outside projects (color) = \", sum_out_color / n_out_color)\n",
    "    print(\"avg weight (color) = \", (sum_in_color + sum_out_color) / (n_in_color + n_out_color) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_statistics(G, ups, ['339', '241'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_proj, node_colors, edge_colors = proj_graph(G, ups, ['339', '241'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the training and test MSE of the regression method,\n",
    "#Something similar can be done in the cross validation.\n",
    "\n",
    "train_perc = 0.5\n",
    "n_samples = A.shape[0]\n",
    "n_samples_train = int(n_samples * train_perc)\n",
    "\n",
    "shuff = np.arange(n_samples)\n",
    "np.random.shuffle(shuff)\n",
    "\n",
    "A = A[shuff]\n",
    "b = b[shuff]\n",
    "\n",
    "m = learn_model(A[0:n_samples_train,:],b[0:n_samples_train], 'gb')\n",
    "\n",
    "print(\"training MSE = \", ((b[:n_samples_train]- m.predict(A[0:n_samples_train,:]))**2).mean(axis=0) )\n",
    "\n",
    "print(\"test MSE = \", ((b[n_samples_train:]- m.predict(A[n_samples_train:,:]))**2).mean(axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
